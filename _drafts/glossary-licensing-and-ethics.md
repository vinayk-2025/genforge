---
title: ""Glossary - Licensing, Bias, and Ethical AI""
description: "Key terms for understanding open-source licensing, model bias, adversarial robustness, and ethical alignment in GenAI"
author: "Satya Prakash Nigam"
tags: [AI Ethics, Licensing, Bias, XAI, Value Alignment, Adversarial Robustness, CC BY-NC]
layout: post
permalink: /glossary/glossary-licensing-and-ethics/
---

# Glossary - Licensing, Bias, and Ethical AI
**Reference for Lecture 4B and Capstone Ethics Discussions**

This glossary defines key terms related to licensing, bias, safety, and ethical alignment in GenAI systems. These concepts support responsible deployment and critical evaluation of AI models.

---

## Licensing Terminology

| Term                     | Description                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| Open-Source License      | Legal framework allowing free use, modification, and distribution of software |
| MIT License              | Permissive license allowing reuse with minimal restrictions                 |
| Apache License 2.0       | Open-source license with patent protection and attribution requirements     |
| Creative Commons (CC)    | Licensing framework for sharing creative works with varying permissions     |
| CC BY-NC 4.0             | Allows sharing and adaptation with attribution, but prohibits commercial use |
| Commercial License       | Restricts usage to paid or authorised contexts, often with proprietary terms |
| Model Card               | Documentation describing an AI model's purpose, limitations, and ethical considerations |
| Attribution              | Requirement to credit the original creator or source when reusing content   |

---

## Bias and Safety Terminology

| Term                     | Description                                                                 |
|--------------------------|-----------------------------------------------------------------------------|
| Model Bias               | Systematic errors or unfair outcomes based on training data or design       |
| Hallucination            | AI-generated output that is plausible (reasonable) but factually incorrect               |
| Adversarial Robustness   | Model's ability to resist manipulation or malicious inputs                  |
| Explainable AI (XAI)     | Techniques that make AI decisions transparent and interpretable             |
| Value Alignment          | Ensuring AI systems reflect human values and ethical principles             |
| X-risk                   | Potential existential risks posed by highly advanced AI systems             |
| Red Teaming              | Stress-testing AI systems for safety, bias, and failure modes               |
| Human Oversight          | Involving humans in monitoring and correcting AI decisions                  |
| Ethical Deployment       | Responsible release and use of AI systems with safeguards and transparency  |
| Consent and Privacy      | Ensuring user data is handled with permission and confidentiality           |

---

## Student Reflection Prompts

- Why is licensing important when using or sharing GenAI models?
- How can bias in training data affect real-world outcomes?
- What safeguards are needed to prevent hallucinations in critical applications?
- How does XAI improve trust in AI systems?
- What ethical responsibilities do developers have when deploying autonomous systems?

---

## Instructor Notes

Use this glossary to scaffold Lecture 4B and capstone ethics discussions. Encourage students to explore model cards, licensing terms, and bias mitigation strategies. Reinforce the importance of transparency and accountability in GenAI workflows.

---

Curated by **Satya Prakash Nigam**  
Independent AI Consultant ¬∑ Fractional CTO ¬∑ Product Architect ¬∑ Technical Enablement Strategist  
üåê Personal: [spnigam.in](https://spnigam.in)  
üß™ Platform: [aialchemyhub.in](https://www.aialchemyhub.in)  
üì∫ YouTube: [AI Alchemy Hub](https://www.youtube.com/@AIAlchemyHub-zx6lz)  
üí¨ Community (Coming Soon): [community.aialchemyhub.in](https://community.aialchemyhub.in)  
üí¨ Zulip: [aialchemyhub.zulipchat.com](https://aialchemyhub.zulipchat.com)  
üìß Email: spnigam25@yahoo.com  
üîó LinkedIn: [linkedin.com/in/spn25](https://www.linkedin.com/in/spn25)  
üíª GitHub: [github.com/satya25](https://github.com/satya25)  
ü§ñ Hugging Face: [huggingface.co/satya25](https://huggingface.co/satya25)

---
