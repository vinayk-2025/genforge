
# Generative AI, Prompt Engineering & Agentic Systems - Student Notes  
**Day 01 / Lecture 01: Foundations, Orientation & Environment Setup**


## ‚úÖ Learning Objectives

By the end of this session, you should be able to:

- Explain the difference between GenAI and traditional AI  
- Describe agentic AI systems and their components  
- Identify and install key tools: Python, LangChain, Hugging Face, Ollama, Gemini CLI  
- Configure and validate your local environment (Python, Node.js, Git, MySQL)  
- Deliver prompts via Web UI, CLI, Python scripting, and Python API  
- Apply prompt styles: zero-shot, few-shot, chain-of-thought, instructional, role-based  
- Deploy a GenAI app using Streamlit Cloud  
- Maintain GitHub hygiene and reproducibility using `requirements.txt`  
- Document workflows and share via GitHub Pages  


## üõ†Ô∏è Tools Introduced & Validated

| Tool / Platform     | Purpose                                      |
|---------------------|----------------------------------------------|
| Python              | Core programming language for GenAI workflows |
| Node.js             | Required for Gemini CLI                      |
| LangChain           | Agentic workflows and chaining logic         |
| Hugging Face        | Access to models and APIs                    |
| Ollama              | Local LLM runtime                            |
| Gemini CLI          | Prompt experimentation with Gemini models    |
| FastAPI             | RESTful API wrapper for GenAI chains         |
| Streamlit           | Interactive GenAI dashboards                 |
| Streamlit Cloud     | Hosting GenAI apps with interactive UI       |
| GitHub              | Version control and collaboration            |
| GitHub Pages        | Hosting markdown documentation and showcases |
| XAMPP               | MySQL-backed prompt workflows                |


## üöÄ Prompt Delivery Methods

| Method         | Description                          |
|----------------|--------------------------------------|
| Web UI         | Paste into Copilot, ChatGPT, etc.    |
| CLI            | Pipe via shell or curl               |
| Python Script  | Embed prompt in code                 |
| Python API     | Send via `requests` or SDK           |


## ‚ö° Exercises to Complete

- Set up and validate your Python, Node.js, and local LLM runtimes  
- Run all validation scripts and confirm environment readiness  
- Explore prompt delivery via all four methods  
- Test LangChain and Gemini CLI workflows via CLI, FastAPI, and Streamlit  
- Deploy a sample GenAI app to Streamlit Cloud  
- Create a reproducible folder with `requirements.txt` and `README.md`  
- Maintain folder hygiene and commit changes to GitHub  
- Share your prompt experiments via GitHub Pages  
- Submit screenshots via LMS or GitHub issue tracker  


## üìå Summary

- You've understood the foundations of GenAI and agentic AI  
- Your local environment is validated and ready for experimentation  
- You've practiced prompt engineering styles and delivery workflows  
- You've deployed and documented your first GenAI app  
- You've begun cultivating reproducible, professional habits for agentic workflows  


Curated by **Satya Prakash Nigam**  
Independent AI Consultant ¬∑ Fractional CTO ¬∑ Product Architect ¬∑ Technical Enablement Strategist  

üåê Personal: [spnigam.in](https://spnigam.in)  
üì° Platform: [aialchemyhub.in](https://www.aialchemyhub.in)  
‚ñ∂Ô∏è YouTube: [AI Alchemy Hub](https://www.youtube.com/@AIAlchemyHub-zx6lz)  
üë• Community (Coming Soon): [community.aialchemyhub.in](https://community.aialchemyhub.in)  
üí¨ Zulip: [aialchemyhub.zulipchat.com](https://aialchemyhub.zulipchat.com)  
‚úâÔ∏è Email: spnigam25@yahoo.com  
üîó LinkedIn: [linkedin.com/in/spn25](https://www.linkedin.com/in/spn25)  
üíª GitHub: [github.com/satya25](https://github.com/satya25)  
ü§ó Hugging Face: [huggingface.co/satya25](https://huggingface.co/satya25)  

**GenForge - Forging the future of agentic AI**  
_Last updated: November 2025_
